[2024-05-03 16:56:34,707][flwr][INFO] - Starting Flower simulation, config: ServerConfig(num_rounds=100, round_timeout=None)
[2024-05-03 16:56:36,039][flwr][INFO] - Flower VCE: Ray initialized with resources: {'node:172.17.34.49': 1.0, 'node:__internal_head__': 1.0, 'memory': 38707789824.0, 'GPU': 4.0, 'accelerator_type:G': 1.0, 'object_store_memory': 19353894912.0, 'CPU': 20.0}
[2024-05-03 16:56:36,039][flwr][INFO] - Initializing global parameters
[2024-05-03 16:56:36,039][flwr][INFO] - Requesting initial parameters from one random client
[2024-05-03 16:56:38,667][flwr][INFO] - Received initial parameters from one random client
[2024-05-03 16:56:38,669][flwr][INFO] - Evaluating initial parameters
[2024-05-03 16:56:46,481][flwr][INFO] - initial parameters (loss, other metrics): 3617.2269020080566, {'accuracy': 0.0977}
[2024-05-03 16:56:46,482][flwr][INFO] - FL starting
[2024-05-03 16:56:46,482][flwr][DEBUG] - fit_round 1: strategy sampled 1 clients (out of 50)
[2024-05-03 16:56:53,721][flwr][DEBUG] - fit_round 1 received 1 results and 0 failures
[2024-05-03 16:56:53,910][flwr][WARNING] - No fit_metrics_aggregation_fn provided
[2024-05-03 16:56:59,089][flwr][INFO] - fit progress: (1, 168.93690180778503, {'accuracy': 0.2404}, 12.607692278921604)
[2024-05-03 16:56:59,090][flwr][DEBUG] - evaluate_round 1: strategy sampled 5 clients (out of 50)
[2024-05-03 16:57:13,540][flwr][DEBUG] - evaluate_round 1 received 5 results and 0 failures
[2024-05-03 16:57:13,540][flwr][WARNING] - No evaluate_metrics_aggregation_fn provided
[2024-05-03 16:57:13,540][flwr][DEBUG] - fit_round 2: strategy sampled 1 clients (out of 50)
[2024-05-03 16:57:18,782][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4042613, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 9.78 GiB total capacity; 285.28 MiB already allocated; 39.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 16:57:18,783][flwr][DEBUG] - fit_round 2 received 0 results and 1 failures
[2024-05-03 16:57:24,015][flwr][INFO] - fit progress: (2, 168.93690180778503, {'accuracy': 0.2404}, 37.533231388777494)
[2024-05-03 16:57:24,015][flwr][DEBUG] - evaluate_round 2: strategy sampled 5 clients (out of 50)
[2024-05-03 16:57:30,789][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4042993, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:57:32,494][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4043312, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:57:34,175][flwr][DEBUG] - evaluate_round 2 received 3 results and 2 failures
[2024-05-03 16:57:34,176][flwr][DEBUG] - fit_round 3: strategy sampled 1 clients (out of 50)
[2024-05-03 16:57:36,804][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4043563, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:57:36,805][flwr][DEBUG] - fit_round 3 received 0 results and 1 failures
[2024-05-03 16:57:42,000][flwr][INFO] - fit progress: (3, 168.93690180778503, {'accuracy': 0.2404}, 55.51858587190509)
[2024-05-03 16:57:42,000][flwr][DEBUG] - evaluate_round 3: strategy sampled 5 clients (out of 50)
[2024-05-03 16:57:56,221][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4044263, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 16:57:56,222][flwr][DEBUG] - evaluate_round 3 received 4 results and 1 failures
[2024-05-03 16:57:56,223][flwr][DEBUG] - fit_round 4: strategy sampled 1 clients (out of 50)
[2024-05-03 16:58:00,033][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4044388, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 16:58:00,034][flwr][DEBUG] - fit_round 4 received 0 results and 1 failures
[2024-05-03 16:58:05,259][flwr][INFO] - fit progress: (4, 168.93690180778503, {'accuracy': 0.2404}, 78.7777255885303)
[2024-05-03 16:58:05,260][flwr][DEBUG] - evaluate_round 4: strategy sampled 5 clients (out of 50)
[2024-05-03 16:58:20,208][flwr][DEBUG] - evaluate_round 4 received 5 results and 0 failures
[2024-05-03 16:58:20,209][flwr][DEBUG] - fit_round 5: strategy sampled 1 clients (out of 50)
[2024-05-03 16:58:25,531][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4045287, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 9.78 GiB total capacity; 285.28 MiB already allocated; 6.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 16:58:25,531][flwr][DEBUG] - fit_round 5 received 0 results and 1 failures
[2024-05-03 16:58:30,762][flwr][INFO] - fit progress: (5, 168.93690180778503, {'accuracy': 0.2404}, 104.27989307790995)
[2024-05-03 16:58:30,762][flwr][DEBUG] - evaluate_round 5: strategy sampled 5 clients (out of 50)
[2024-05-03 16:58:37,416][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4045663, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:58:38,999][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4045961, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:58:41,146][flwr][DEBUG] - evaluate_round 5 received 3 results and 2 failures
[2024-05-03 16:58:41,147][flwr][DEBUG] - fit_round 6: strategy sampled 1 clients (out of 50)
[2024-05-03 16:58:43,660][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4046208, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:58:43,661][flwr][DEBUG] - fit_round 6 received 0 results and 1 failures
[2024-05-03 16:58:48,862][flwr][INFO] - fit progress: (6, 168.93690180778503, {'accuracy': 0.2404}, 122.38068528845906)
[2024-05-03 16:58:48,863][flwr][DEBUG] - evaluate_round 6: strategy sampled 5 clients (out of 50)
[2024-05-03 16:59:01,891][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4046890, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 16:59:01,892][flwr][DEBUG] - evaluate_round 6 received 4 results and 1 failures
[2024-05-03 16:59:01,893][flwr][DEBUG] - fit_round 7: strategy sampled 1 clients (out of 50)
[2024-05-03 16:59:04,400][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4047007, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:59:04,401][flwr][DEBUG] - fit_round 7 received 0 results and 1 failures
[2024-05-03 16:59:09,625][flwr][INFO] - fit progress: (7, 168.93690180778503, {'accuracy': 0.2404}, 143.14289074391127)
[2024-05-03 16:59:09,625][flwr][DEBUG] - evaluate_round 7: strategy sampled 5 clients (out of 50)
[2024-05-03 16:59:24,180][flwr][DEBUG] - evaluate_round 7 received 5 results and 0 failures
[2024-05-03 16:59:24,181][flwr][DEBUG] - fit_round 8: strategy sampled 1 clients (out of 50)
[2024-05-03 16:59:29,572][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4047850, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 9.78 GiB total capacity; 285.28 MiB already allocated; 12.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 16:59:29,573][flwr][DEBUG] - fit_round 8 received 0 results and 1 failures
[2024-05-03 16:59:34,801][flwr][INFO] - fit progress: (8, 168.93690180778503, {'accuracy': 0.2404}, 168.31945150345564)
[2024-05-03 16:59:34,801][flwr][DEBUG] - evaluate_round 8: strategy sampled 5 clients (out of 50)
[2024-05-03 16:59:41,463][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4048231, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:59:46,380][flwr][DEBUG] - evaluate_round 8 received 4 results and 1 failures
[2024-05-03 16:59:46,381][flwr][DEBUG] - fit_round 9: strategy sampled 1 clients (out of 50)
[2024-05-03 16:59:48,859][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4048893, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 16:59:48,859][flwr][DEBUG] - fit_round 9 received 0 results and 1 failures
[2024-05-03 16:59:54,081][flwr][INFO] - fit progress: (9, 168.93690180778503, {'accuracy': 0.2404}, 187.59917425364256)
[2024-05-03 16:59:54,081][flwr][DEBUG] - evaluate_round 9: strategy sampled 5 clients (out of 50)
[2024-05-03 17:00:01,832][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4049127, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:00:03,534][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4049519, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:00:04,033][flwr][DEBUG] - evaluate_round 9 received 3 results and 2 failures
[2024-05-03 17:00:04,034][flwr][DEBUG] - fit_round 10: strategy sampled 1 clients (out of 50)
[2024-05-03 17:00:06,585][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4049694, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:00:06,585][flwr][DEBUG] - fit_round 10 received 0 results and 1 failures
[2024-05-03 17:00:11,802][flwr][INFO] - fit progress: (10, 168.93690180778503, {'accuracy': 0.2404}, 205.32009968534112)
[2024-05-03 17:00:11,802][flwr][DEBUG] - evaluate_round 10: strategy sampled 5 clients (out of 50)
[2024-05-03 17:00:26,737][flwr][DEBUG] - evaluate_round 10 received 5 results and 0 failures
[2024-05-03 17:00:26,738][flwr][DEBUG] - fit_round 11: strategy sampled 1 clients (out of 50)
[2024-05-03 17:00:31,952][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4050440, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 9.78 GiB total capacity; 285.28 MiB already allocated; 10.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:00:31,953][flwr][DEBUG] - fit_round 11 received 0 results and 1 failures
[2024-05-03 17:00:37,171][flwr][INFO] - fit progress: (11, 168.93690180778503, {'accuracy': 0.2404}, 230.68966253474355)
[2024-05-03 17:00:37,171][flwr][DEBUG] - evaluate_round 11: strategy sampled 5 clients (out of 50)
[2024-05-03 17:00:49,135][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4051315, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:00:49,136][flwr][DEBUG] - evaluate_round 11 received 4 results and 1 failures
[2024-05-03 17:00:49,136][flwr][DEBUG] - fit_round 12: strategy sampled 1 clients (out of 50)
[2024-05-03 17:00:51,562][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4051375, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:00:51,563][flwr][DEBUG] - fit_round 12 received 0 results and 1 failures
[2024-05-03 17:00:56,793][flwr][INFO] - fit progress: (12, 168.93690180778503, {'accuracy': 0.2404}, 250.31167209893465)
[2024-05-03 17:00:56,794][flwr][DEBUG] - evaluate_round 12: strategy sampled 5 clients (out of 50)
[2024-05-03 17:01:05,282][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4051709, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:01:07,016][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4052099, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:01:07,236][flwr][DEBUG] - evaluate_round 12 received 3 results and 2 failures
[2024-05-03 17:01:07,237][flwr][DEBUG] - fit_round 13: strategy sampled 1 clients (out of 50)
[2024-05-03 17:01:09,802][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4052271, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:01:09,803][flwr][DEBUG] - fit_round 13 received 0 results and 1 failures
[2024-05-03 17:01:15,059][flwr][INFO] - fit progress: (13, 168.93690180778503, {'accuracy': 0.2404}, 268.5773134306073)
[2024-05-03 17:01:15,059][flwr][DEBUG] - evaluate_round 13: strategy sampled 5 clients (out of 50)
[2024-05-03 17:01:29,660][flwr][DEBUG] - evaluate_round 13 received 5 results and 0 failures
[2024-05-03 17:01:29,661][flwr][DEBUG] - fit_round 14: strategy sampled 1 clients (out of 50)
[2024-05-03 17:01:35,080][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4053051, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 9.78 GiB total capacity; 285.28 MiB already allocated; 8.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:01:35,081][flwr][DEBUG] - fit_round 14 received 0 results and 1 failures
[2024-05-03 17:01:40,332][flwr][INFO] - fit progress: (14, 168.93690180778503, {'accuracy': 0.2404}, 293.85084461793303)
[2024-05-03 17:01:40,333][flwr][DEBUG] - evaluate_round 14: strategy sampled 5 clients (out of 50)
[2024-05-03 17:01:54,454][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4053880, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 17:01:54,455][flwr][DEBUG] - evaluate_round 14 received 4 results and 1 failures
[2024-05-03 17:01:54,456][flwr][DEBUG] - fit_round 15: strategy sampled 1 clients (out of 50)
[2024-05-03 17:01:56,985][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4054011, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:01:56,986][flwr][DEBUG] - fit_round 15 received 0 results and 1 failures
[2024-05-03 17:02:02,264][flwr][INFO] - fit progress: (15, 168.93690180778503, {'accuracy': 0.2404}, 315.7822864279151)
[2024-05-03 17:02:02,264][flwr][DEBUG] - evaluate_round 15: strategy sampled 5 clients (out of 50)
[2024-05-03 17:02:10,803][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4054328, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:02:12,609][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4054717, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:02:12,753][flwr][DEBUG] - evaluate_round 15 received 3 results and 2 failures
[2024-05-03 17:02:12,753][flwr][DEBUG] - fit_round 16: strategy sampled 1 clients (out of 50)
[2024-05-03 17:02:15,499][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4054875, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:02:15,500][flwr][DEBUG] - fit_round 16 received 0 results and 1 failures
[2024-05-03 17:02:20,733][flwr][INFO] - fit progress: (16, 168.93690180778503, {'accuracy': 0.2404}, 334.25158970057964)
[2024-05-03 17:02:20,733][flwr][DEBUG] - evaluate_round 16: strategy sampled 5 clients (out of 50)
[2024-05-03 17:02:35,989][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4055504, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 9.78 GiB total capacity; 249.27 MiB already allocated; 32.56 MiB free; 284.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:02:35,990][flwr][DEBUG] - evaluate_round 16 received 4 results and 1 failures
[2024-05-03 17:02:35,991][flwr][DEBUG] - fit_round 17: strategy sampled 1 clients (out of 50)
[2024-05-03 17:02:38,545][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4055625, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:02:38,545][flwr][DEBUG] - fit_round 17 received 0 results and 1 failures
[2024-05-03 17:02:43,772][flwr][INFO] - fit progress: (17, 168.93690180778503, {'accuracy': 0.2404}, 357.29024079814553)
[2024-05-03 17:02:43,772][flwr][DEBUG] - evaluate_round 17: strategy sampled 5 clients (out of 50)
[2024-05-03 17:02:55,288][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4056346, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:02:55,289][flwr][DEBUG] - evaluate_round 17 received 4 results and 1 failures
[2024-05-03 17:02:55,290][flwr][DEBUG] - fit_round 18: strategy sampled 1 clients (out of 50)
[2024-05-03 17:02:57,846][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4056420, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:02:57,846][flwr][DEBUG] - fit_round 18 received 0 results and 1 failures
[2024-05-03 17:03:03,108][flwr][INFO] - fit progress: (18, 168.93690180778503, {'accuracy': 0.2404}, 376.626349195838)
[2024-05-03 17:03:03,108][flwr][DEBUG] - evaluate_round 18: strategy sampled 5 clients (out of 50)
[2024-05-03 17:03:11,883][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4056755, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:03:13,705][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4057144, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:03:13,823][flwr][DEBUG] - evaluate_round 18 received 3 results and 2 failures
[2024-05-03 17:03:13,823][flwr][DEBUG] - fit_round 19: strategy sampled 1 clients (out of 50)
[2024-05-03 17:03:19,250][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4057297, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 9.78 GiB total capacity; 435.48 MiB already allocated; 10.56 MiB free; 496.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:03:19,251][flwr][DEBUG] - fit_round 19 received 0 results and 1 failures
[2024-05-03 17:03:24,495][flwr][INFO] - fit progress: (19, 168.93690180778503, {'accuracy': 0.2404}, 398.01323360577226)
[2024-05-03 17:03:24,495][flwr][DEBUG] - evaluate_round 19: strategy sampled 5 clients (out of 50)
[2024-05-03 17:03:35,147][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4057663, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 128, in forward
    weight_b=binarized(self.weight)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 217.74 MiB already allocated; 12.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:03:36,642][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4058066, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:03:36,643][flwr][DEBUG] - evaluate_round 19 received 3 results and 2 failures
[2024-05-03 17:03:36,643][flwr][DEBUG] - fit_round 20: strategy sampled 1 clients (out of 50)
[2024-05-03 17:03:39,246][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4058216, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:03:39,246][flwr][DEBUG] - fit_round 20 received 0 results and 1 failures
[2024-05-03 17:03:44,513][flwr][INFO] - fit progress: (20, 168.93690180778503, {'accuracy': 0.2404}, 418.03089310601354)
[2024-05-03 17:03:44,513][flwr][DEBUG] - evaluate_round 20: strategy sampled 5 clients (out of 50)
[2024-05-03 17:03:55,953][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4058846, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:03:55,954][flwr][DEBUG] - evaluate_round 20 received 4 results and 1 failures
[2024-05-03 17:03:55,954][flwr][DEBUG] - fit_round 21: strategy sampled 1 clients (out of 50)
[2024-05-03 17:03:58,435][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4058920, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:03:58,435][flwr][DEBUG] - fit_round 21 received 0 results and 1 failures
[2024-05-03 17:04:03,660][flwr][INFO] - fit progress: (21, 168.93690180778503, {'accuracy': 0.2404}, 437.1782357990742)
[2024-05-03 17:04:03,660][flwr][DEBUG] - evaluate_round 21: strategy sampled 5 clients (out of 50)
[2024-05-03 17:04:18,561][flwr][DEBUG] - evaluate_round 21 received 5 results and 0 failures
[2024-05-03 17:04:18,561][flwr][DEBUG] - fit_round 22: strategy sampled 1 clients (out of 50)
[2024-05-03 17:04:22,390][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4059790, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:04:22,390][flwr][DEBUG] - fit_round 22 received 0 results and 1 failures
[2024-05-03 17:04:27,667][flwr][INFO] - fit progress: (22, 168.93690180778503, {'accuracy': 0.2404}, 461.18514742329717)
[2024-05-03 17:04:27,667][flwr][DEBUG] - evaluate_round 22: strategy sampled 5 clients (out of 50)
[2024-05-03 17:04:38,348][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4060139, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 128, in forward
    weight_b=binarized(self.weight)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 217.74 MiB already allocated; 10.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:04:39,887][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4060535, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:04:39,889][flwr][DEBUG] - evaluate_round 22 received 3 results and 2 failures
[2024-05-03 17:04:39,889][flwr][DEBUG] - fit_round 23: strategy sampled 1 clients (out of 50)
[2024-05-03 17:04:42,490][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4060689, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:04:42,491][flwr][DEBUG] - fit_round 23 received 0 results and 1 failures
[2024-05-03 17:04:47,711][flwr][INFO] - fit progress: (23, 168.93690180778503, {'accuracy': 0.2404}, 481.2296646758914)
[2024-05-03 17:04:47,711][flwr][DEBUG] - evaluate_round 23: strategy sampled 5 clients (out of 50)
[2024-05-03 17:04:59,594][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4061324, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:04:59,595][flwr][DEBUG] - evaluate_round 23 received 4 results and 1 failures
[2024-05-03 17:04:59,595][flwr][DEBUG] - fit_round 24: strategy sampled 1 clients (out of 50)
[2024-05-03 17:05:02,201][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4061428, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:05:02,202][flwr][DEBUG] - fit_round 24 received 0 results and 1 failures
[2024-05-03 17:05:07,457][flwr][INFO] - fit progress: (24, 168.93690180778503, {'accuracy': 0.2404}, 500.97507298737764)
[2024-05-03 17:05:07,457][flwr][DEBUG] - evaluate_round 24: strategy sampled 5 clients (out of 50)
[2024-05-03 17:05:22,302][flwr][DEBUG] - evaluate_round 24 received 5 results and 0 failures
[2024-05-03 17:05:22,302][flwr][DEBUG] - fit_round 25: strategy sampled 1 clients (out of 50)
[2024-05-03 17:05:26,085][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4062240, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:05:26,086][flwr][DEBUG] - fit_round 25 received 0 results and 1 failures
[2024-05-03 17:05:31,336][flwr][INFO] - fit progress: (25, 168.93690180778503, {'accuracy': 0.2404}, 524.8547799177468)
[2024-05-03 17:05:31,337][flwr][DEBUG] - evaluate_round 25: strategy sampled 5 clients (out of 50)
[2024-05-03 17:05:41,860][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4062611, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 128, in forward
    weight_b=binarized(self.weight)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 217.74 MiB already allocated; 12.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:05:45,698][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4063012, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 17:05:45,699][flwr][DEBUG] - evaluate_round 25 received 3 results and 2 failures
[2024-05-03 17:05:45,700][flwr][DEBUG] - fit_round 26: strategy sampled 1 clients (out of 50)
[2024-05-03 17:05:48,253][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4063208, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:05:48,254][flwr][DEBUG] - fit_round 26 received 0 results and 1 failures
[2024-05-03 17:05:53,524][flwr][INFO] - fit progress: (26, 168.93690180778503, {'accuracy': 0.2404}, 547.0424781702459)
[2024-05-03 17:05:53,524][flwr][DEBUG] - evaluate_round 26: strategy sampled 5 clients (out of 50)
[2024-05-03 17:06:05,615][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4063929, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:06:05,616][flwr][DEBUG] - evaluate_round 26 received 4 results and 1 failures
[2024-05-03 17:06:05,616][flwr][DEBUG] - fit_round 27: strategy sampled 1 clients (out of 50)
[2024-05-03 17:06:08,201][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4064033, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:06:08,202][flwr][DEBUG] - fit_round 27 received 0 results and 1 failures
[2024-05-03 17:06:13,455][flwr][INFO] - fit progress: (27, 168.93690180778503, {'accuracy': 0.2404}, 566.9730655513704)
[2024-05-03 17:06:13,455][flwr][DEBUG] - evaluate_round 27: strategy sampled 5 clients (out of 50)
[2024-05-03 17:06:26,415][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4064723, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:06:26,416][flwr][DEBUG] - evaluate_round 27 received 4 results and 1 failures
[2024-05-03 17:06:26,417][flwr][DEBUG] - fit_round 28: strategy sampled 1 clients (out of 50)
[2024-05-03 17:06:28,922][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4064844, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:06:28,923][flwr][DEBUG] - fit_round 28 received 0 results and 1 failures
[2024-05-03 17:06:34,146][flwr][INFO] - fit progress: (28, 168.93690180778503, {'accuracy': 0.2404}, 587.6644656285644)
[2024-05-03 17:06:34,146][flwr][DEBUG] - evaluate_round 28: strategy sampled 5 clients (out of 50)
[2024-05-03 17:06:43,926][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4065168, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 128, in forward
    weight_b=binarized(self.weight)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 217.74 MiB already allocated; 6.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:06:45,445][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4065561, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:06:45,445][flwr][DEBUG] - evaluate_round 28 received 3 results and 2 failures
[2024-05-03 17:06:45,446][flwr][DEBUG] - fit_round 29: strategy sampled 1 clients (out of 50)
[2024-05-03 17:06:47,990][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4065718, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:06:47,990][flwr][DEBUG] - fit_round 29 received 0 results and 1 failures
[2024-05-03 17:06:53,220][flwr][INFO] - fit progress: (29, 168.93690180778503, {'accuracy': 0.2404}, 606.7383149750531)
[2024-05-03 17:06:53,220][flwr][DEBUG] - evaluate_round 29: strategy sampled 5 clients (out of 50)
[2024-05-03 17:07:08,035][flwr][DEBUG] - evaluate_round 29 received 5 results and 0 failures
[2024-05-03 17:07:08,036][flwr][DEBUG] - fit_round 30: strategy sampled 1 clients (out of 50)
[2024-05-03 17:07:10,597][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4066491, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:07:10,597][flwr][DEBUG] - fit_round 30 received 0 results and 1 failures
[2024-05-03 17:07:15,834][flwr][INFO] - fit progress: (30, 168.93690180778503, {'accuracy': 0.2404}, 629.3523883186281)
[2024-05-03 17:07:15,834][flwr][DEBUG] - evaluate_round 30: strategy sampled 5 clients (out of 50)
[2024-05-03 17:07:30,672][flwr][DEBUG] - evaluate_round 30 received 5 results and 0 failures
[2024-05-03 17:07:30,673][flwr][DEBUG] - fit_round 31: strategy sampled 1 clients (out of 50)
[2024-05-03 17:07:34,462][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4067317, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
[2024-05-03 17:07:34,463][flwr][DEBUG] - fit_round 31 received 0 results and 1 failures
[2024-05-03 17:07:39,709][flwr][INFO] - fit progress: (31, 168.93690180778503, {'accuracy': 0.2404}, 653.2275126315653)
[2024-05-03 17:07:39,709][flwr][DEBUG] - evaluate_round 31: strategy sampled 5 clients (out of 50)
[2024-05-03 17:07:50,172][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4067693, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 128, in forward
    weight_b=binarized(self.weight)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 217.74 MiB already allocated; 8.56 MiB free; 290.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:07:57,974][flwr][ERROR] - Task was killed due to the node running low on memory.
Memory on the node (IP: 172.17.34.49, ID: d1ed8acdbae52d29289518b16a7f9b69ead392726668d7a9380869aa) where the task (task ID: 56e58566df0f08a678c0cd384f2069640316d99701000000, name=launch_and_evaluate, pid=4068092, memory used=1.54GB) was running was 59.47GB / 62.50GB (0.951531), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 7a221bb1e41329f2878567fd5cb5c67f8e659c35fb42ed7fbfbaac2f) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.34.49`. To see the logs of the worker, use `ray logs worker-7a221bb1e41329f2878567fd5cb5c67f8e659c35fb42ed7fbfbaac2f*out -ip 172.17.34.49. Top 10 memory users:
PID	MEM(GB)	COMMAND
4040040	4.06	python main.py
4066352	3.28	ray::IDLE
4065961	3.27	ray::IDLE
4067741	3.27	ray::IDLE
4066804	3.27	ray::IDLE
4065959	3.27	ray::IDLE
4067742	3.27	ray::IDLE
4067695	3.27	ray::IDLE
4067195	3.27	ray::IDLE
4066806	3.27	ray::IDLE
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2024-05-03 17:07:57,974][flwr][DEBUG] - evaluate_round 31 received 3 results and 2 failures
[2024-05-03 17:07:57,975][flwr][DEBUG] - fit_round 32: strategy sampled 1 clients (out of 50)
[2024-05-03 17:08:01,526][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4068392, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:08:01,526][flwr][DEBUG] - fit_round 32 received 0 results and 1 failures
[2024-05-03 17:08:06,772][flwr][INFO] - fit progress: (32, 168.93690180778503, {'accuracy': 0.2404}, 680.2903108932078)
[2024-05-03 17:08:06,772][flwr][DEBUG] - evaluate_round 32: strategy sampled 5 clients (out of 50)
[2024-05-03 17:08:21,269][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4069116, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 17:08:21,270][flwr][DEBUG] - evaluate_round 32 received 4 results and 1 failures
[2024-05-03 17:08:21,270][flwr][DEBUG] - fit_round 33: strategy sampled 1 clients (out of 50)
[2024-05-03 17:08:23,731][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4069228, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:08:23,732][flwr][DEBUG] - fit_round 33 received 0 results and 1 failures
[2024-05-03 17:08:28,957][flwr][INFO] - fit progress: (33, 168.93690180778503, {'accuracy': 0.2404}, 702.4749823026359)
[2024-05-03 17:08:28,957][flwr][DEBUG] - evaluate_round 33: strategy sampled 5 clients (out of 50)
[2024-05-03 17:08:44,118][flwr][DEBUG] - evaluate_round 33 received 5 results and 0 failures
[2024-05-03 17:08:44,118][flwr][DEBUG] - fit_round 34: strategy sampled 1 clients (out of 50)
[2024-05-03 17:08:46,604][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4070179, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:08:46,605][flwr][DEBUG] - fit_round 34 received 0 results and 1 failures
[2024-05-03 17:08:51,823][flwr][INFO] - fit progress: (34, 168.93690180778503, {'accuracy': 0.2404}, 725.3409159891307)
[2024-05-03 17:08:51,823][flwr][DEBUG] - evaluate_round 34: strategy sampled 5 clients (out of 50)
[2024-05-03 17:09:06,697][flwr][DEBUG] - evaluate_round 34 received 5 results and 0 failures
[2024-05-03 17:09:06,697][flwr][DEBUG] - fit_round 35: strategy sampled 1 clients (out of 50)
[2024-05-03 17:09:10,012][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4071023, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:09:10,013][flwr][DEBUG] - fit_round 35 received 0 results and 1 failures
[2024-05-03 17:09:15,269][flwr][INFO] - fit progress: (35, 168.93690180778503, {'accuracy': 0.2404}, 748.7877777591348)
[2024-05-03 17:09:15,270][flwr][DEBUG] - evaluate_round 35: strategy sampled 5 clients (out of 50)
[2024-05-03 17:09:29,587][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4071748, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 17:09:29,588][flwr][DEBUG] - evaluate_round 35 received 4 results and 1 failures
[2024-05-03 17:09:29,589][flwr][DEBUG] - fit_round 36: strategy sampled 1 clients (out of 50)
[2024-05-03 17:09:32,844][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4071860, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:09:32,845][flwr][DEBUG] - fit_round 36 received 0 results and 1 failures
[2024-05-03 17:09:38,087][flwr][INFO] - fit progress: (36, 168.93690180778503, {'accuracy': 0.2404}, 771.6054711192846)
[2024-05-03 17:09:38,087][flwr][DEBUG] - evaluate_round 36: strategy sampled 5 clients (out of 50)
[2024-05-03 17:09:53,804][flwr][DEBUG] - evaluate_round 36 received 5 results and 0 failures
[2024-05-03 17:09:53,804][flwr][DEBUG] - fit_round 37: strategy sampled 1 clients (out of 50)
[2024-05-03 17:09:57,264][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4072732, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:09:57,265][flwr][DEBUG] - fit_round 37 received 0 results and 1 failures
[2024-05-03 17:10:02,489][flwr][INFO] - fit progress: (37, 168.93690180778503, {'accuracy': 0.2404}, 796.0073952674866)
[2024-05-03 17:10:02,489][flwr][DEBUG] - evaluate_round 37: strategy sampled 5 clients (out of 50)
[2024-05-03 17:10:10,533][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4073011, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:10:12,269][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4073239, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:10:13,258][flwr][DEBUG] - evaluate_round 37 received 3 results and 2 failures
[2024-05-03 17:10:13,259][flwr][DEBUG] - fit_round 38: strategy sampled 1 clients (out of 50)
[2024-05-03 17:10:15,907][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4073534, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:10:15,907][flwr][DEBUG] - fit_round 38 received 0 results and 1 failures
[2024-05-03 17:10:21,162][flwr][INFO] - fit progress: (38, 168.93690180778503, {'accuracy': 0.2404}, 814.6804105006158)
[2024-05-03 17:10:21,162][flwr][DEBUG] - evaluate_round 38: strategy sampled 5 clients (out of 50)
[2024-05-03 17:10:35,418][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4074265, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 17:10:35,419][flwr][DEBUG] - evaluate_round 38 received 4 results and 1 failures
[2024-05-03 17:10:35,420][flwr][DEBUG] - fit_round 39: strategy sampled 1 clients (out of 50)
[2024-05-03 17:10:40,881][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4074381, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 9.78 GiB total capacity; 435.48 MiB already allocated; 22.56 MiB free; 496.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:10:40,882][flwr][DEBUG] - fit_round 39 received 0 results and 1 failures
[2024-05-03 17:10:46,117][flwr][INFO] - fit progress: (39, 168.93690180778503, {'accuracy': 0.2404}, 839.6354104280472)
[2024-05-03 17:10:46,117][flwr][DEBUG] - evaluate_round 39: strategy sampled 5 clients (out of 50)
[2024-05-03 17:11:00,910][flwr][DEBUG] - evaluate_round 39 received 5 results and 0 failures
[2024-05-03 17:11:00,911][flwr][DEBUG] - fit_round 40: strategy sampled 1 clients (out of 50)
[2024-05-03 17:11:06,261][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4075359, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 9.78 GiB total capacity; 435.48 MiB already allocated; 22.56 MiB free; 496.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:11:06,261][flwr][DEBUG] - fit_round 40 received 0 results and 1 failures
[2024-05-03 17:11:11,503][flwr][INFO] - fit progress: (40, 168.93690180778503, {'accuracy': 0.2404}, 865.0209654383361)
[2024-05-03 17:11:11,503][flwr][DEBUG] - evaluate_round 40: strategy sampled 5 clients (out of 50)
[2024-05-03 17:11:27,076][flwr][DEBUG] - evaluate_round 40 received 5 results and 0 failures
[2024-05-03 17:11:27,076][flwr][DEBUG] - fit_round 41: strategy sampled 1 clients (out of 50)
[2024-05-03 17:11:30,329][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4076331, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:11:30,329][flwr][DEBUG] - fit_round 41 received 0 results and 1 failures
[2024-05-03 17:11:35,569][flwr][INFO] - fit progress: (41, 168.93690180778503, {'accuracy': 0.2404}, 889.0870570912957)
[2024-05-03 17:11:35,569][flwr][DEBUG] - evaluate_round 41: strategy sampled 5 clients (out of 50)
[2024-05-03 17:11:43,601][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4076646, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:11:45,359][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4076893, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:11:46,288][flwr][DEBUG] - evaluate_round 41 received 3 results and 2 failures
[2024-05-03 17:11:46,289][flwr][DEBUG] - fit_round 42: strategy sampled 1 clients (out of 50)
[2024-05-03 17:11:48,936][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4077169, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:11:48,937][flwr][DEBUG] - fit_round 42 received 0 results and 1 failures
[2024-05-03 17:11:54,176][flwr][INFO] - fit progress: (42, 168.93690180778503, {'accuracy': 0.2404}, 907.6944868192077)
[2024-05-03 17:11:54,176][flwr][DEBUG] - evaluate_round 42: strategy sampled 5 clients (out of 50)
[2024-05-03 17:12:05,699][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4077882, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:12:05,700][flwr][DEBUG] - evaluate_round 42 received 4 results and 1 failures
[2024-05-03 17:12:05,700][flwr][DEBUG] - fit_round 43: strategy sampled 1 clients (out of 50)
[2024-05-03 17:12:08,295][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4077964, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:12:08,296][flwr][DEBUG] - fit_round 43 received 0 results and 1 failures
[2024-05-03 17:12:13,571][flwr][INFO] - fit progress: (43, 168.93690180778503, {'accuracy': 0.2404}, 927.0892995074391)
[2024-05-03 17:12:13,571][flwr][DEBUG] - evaluate_round 43: strategy sampled 5 clients (out of 50)
[2024-05-03 17:12:28,341][flwr][DEBUG] - evaluate_round 43 received 5 results and 0 failures
[2024-05-03 17:12:28,342][flwr][DEBUG] - fit_round 44: strategy sampled 1 clients (out of 50)
[2024-05-03 17:12:30,990][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4078820, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:12:30,991][flwr][DEBUG] - fit_round 44 received 0 results and 1 failures
[2024-05-03 17:12:36,246][flwr][INFO] - fit progress: (44, 168.93690180778503, {'accuracy': 0.2404}, 949.7640833444893)
[2024-05-03 17:12:36,246][flwr][DEBUG] - evaluate_round 44: strategy sampled 5 clients (out of 50)
[2024-05-03 17:12:43,871][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4079129, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:12:45,656][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4079376, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:12:46,555][flwr][DEBUG] - evaluate_round 44 received 3 results and 2 failures
[2024-05-03 17:12:46,556][flwr][DEBUG] - fit_round 45: strategy sampled 1 clients (out of 50)
[2024-05-03 17:12:51,958][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4079634, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 234, in forward
    return F.hardtanh(input, self.min_val, self.max_val, self.inplace)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/functional.py", line 1506, in hardtanh
    result = torch._C._nn.hardtanh_(input, min_val, max_val)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 9.78 GiB total capacity; 381.48 MiB already allocated; 19.56 MiB free; 442.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:12:51,959][flwr][DEBUG] - fit_round 45 received 0 results and 1 failures
[2024-05-03 17:12:57,204][flwr][INFO] - fit progress: (45, 168.93690180778503, {'accuracy': 0.2404}, 970.7225314378738)
[2024-05-03 17:12:57,204][flwr][DEBUG] - evaluate_round 45: strategy sampled 5 clients (out of 50)
[2024-05-03 17:13:04,026][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4080003, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:13:05,833][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4080208, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:13:07,578][flwr][DEBUG] - evaluate_round 45 received 3 results and 2 failures
[2024-05-03 17:13:07,579][flwr][DEBUG] - fit_round 46: strategy sampled 1 clients (out of 50)
[2024-05-03 17:13:12,944][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4080526, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 90, in train
    loss = criterion(net(images), labels)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 125, in forward
    input_b = binarized(input)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 58, in binarized
    return Binarize.apply(input,quant_mode)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 26, in forward
    return output.div(scale).sign().mul(scale)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 9.78 GiB total capacity; 435.48 MiB already allocated; 21.56 MiB free; 496.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:13:12,945][flwr][DEBUG] - fit_round 46 received 0 results and 1 failures
[2024-05-03 17:13:18,174][flwr][INFO] - fit progress: (46, 168.93690180778503, {'accuracy': 0.2404}, 991.6921539008617)
[2024-05-03 17:13:18,174][flwr][DEBUG] - evaluate_round 46: strategy sampled 5 clients (out of 50)
[2024-05-03 17:13:33,186][flwr][DEBUG] - evaluate_round 46 received 5 results and 0 failures
[2024-05-03 17:13:33,187][flwr][DEBUG] - fit_round 47: strategy sampled 1 clients (out of 50)
[2024-05-03 17:13:35,720][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4081406, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:13:35,721][flwr][DEBUG] - fit_round 47 received 0 results and 1 failures
[2024-05-03 17:13:40,953][flwr][INFO] - fit progress: (47, 168.93690180778503, {'accuracy': 0.2404}, 1014.471001278609)
[2024-05-03 17:13:40,953][flwr][DEBUG] - evaluate_round 47: strategy sampled 5 clients (out of 50)
[2024-05-03 17:13:55,579][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4082131, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 111, in test
    outputs = net(images)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 72, in forward
    x = self.features(x)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/share/home/rkat6291/flwr_bnn_fromt/models/binarized_modules.py", line 130, in forward
    out = nn.functional.conv2d(input_b, weight_b, None, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
[2024-05-03 17:13:55,580][flwr][DEBUG] - evaluate_round 47 received 4 results and 1 failures
[2024-05-03 17:13:55,581][flwr][DEBUG] - fit_round 48: strategy sampled 1 clients (out of 50)
[2024-05-03 17:13:58,832][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4082251, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 22.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:13:58,833][flwr][DEBUG] - fit_round 48 received 0 results and 1 failures
[2024-05-03 17:14:04,052][flwr][INFO] - fit progress: (48, 168.93690180778503, {'accuracy': 0.2404}, 1037.5699103213847)
[2024-05-03 17:14:04,052][flwr][DEBUG] - evaluate_round 48: strategy sampled 5 clients (out of 50)
[2024-05-03 17:14:16,237][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4082977, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:14:16,238][flwr][DEBUG] - evaluate_round 48 received 4 results and 1 failures
[2024-05-03 17:14:16,239][flwr][DEBUG] - fit_round 49: strategy sampled 1 clients (out of 50)
[2024-05-03 17:14:18,750][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4083048, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:14:18,750][flwr][DEBUG] - fit_round 49 received 0 results and 1 failures
[2024-05-03 17:14:23,973][flwr][INFO] - fit progress: (49, 168.93690180778503, {'accuracy': 0.2404}, 1057.4914561919868)
[2024-05-03 17:14:23,973][flwr][DEBUG] - evaluate_round 49: strategy sampled 5 clients (out of 50)
[2024-05-03 17:14:35,747][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=4083774, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 160, in launch_and_evaluate
    return maybe_call_evaluate(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 205, in maybe_call_evaluate
    return client.evaluate(evaluate_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 321, in _evaluate
    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 172, in evaluate
    loss, accuracy = test(self.model, self.valloader, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 107, in test
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:14:35,748][flwr][DEBUG] - evaluate_round 49 received 4 results and 1 failures
[2024-05-03 17:14:35,748][flwr][DEBUG] - fit_round 50: strategy sampled 1 clients (out of 50)
[2024-05-03 17:14:38,325][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4083852, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[2024-05-03 17:14:38,326][flwr][DEBUG] - fit_round 50 received 0 results and 1 failures
[2024-05-03 17:14:43,551][flwr][INFO] - fit progress: (50, 168.93690180778503, {'accuracy': 0.2404}, 1077.0697571747005)
[2024-05-03 17:14:43,552][flwr][DEBUG] - evaluate_round 50: strategy sampled 5 clients (out of 50)
[2024-05-03 17:14:58,332][flwr][DEBUG] - evaluate_round 50 received 5 results and 0 failures
[2024-05-03 17:14:58,333][flwr][DEBUG] - fit_round 51: strategy sampled 1 clients (out of 50)
[2024-05-03 17:15:01,706][flwr][ERROR] - [36mray::launch_and_fit()[39m (pid=4084722, ip=172.17.34.49)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 148, in launch_and_fit
    return maybe_call_fit(
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/client.py", line 184, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/flwr/client/app.py", line 297, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "/share/home/rkat6291/flwr_bnn_fromt/client.py", line 93, in fit
    train(self.model, self.trainloader, optim, epochs, self.device)
  File "/share/home/rkat6291/flwr_bnn_fromt/model_vgg_cifar10_binary.py", line 85, in train
    net.to(device)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/rkat6291/miniconda3/envs/flower_tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 9.78 GiB total capacity; 15.26 MiB already allocated; 20.56 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-05-03 17:15:01,706][flwr][DEBUG] - fit_round 51 received 0 results and 1 failures
[2024-05-03 17:15:06,928][flwr][INFO] - fit progress: (51, 168.93690180778503, {'accuracy': 0.2404}, 1100.4464272037148)
[2024-05-03 17:15:06,928][flwr][DEBUG] - evaluate_round 51: strategy sampled 5 clients (out of 50)
